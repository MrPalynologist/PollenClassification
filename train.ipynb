{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3103bb00-d708-4fe6-a672-322dabcc7998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "import seaborn as sns\n",
    "#from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU, BatchNormalization\n",
    "#from tensorflow.keras import layers, initializers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import ResNet152V2\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dab816-93e7-48b1-b0ae-25b80f23be3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasetpath = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1294f71-a92b-4607-ac78-4cd9695acdb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"tf_gpu_allocator\"]=\"cuda_malloc_async\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95e10e-177d-4214-b1f4-0f0fb6078ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad2f67-4584-4e7b-95ab-9dbc2da77cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d47f5-f56e-41e5-95f4-551377033a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path  = datasetpath\n",
    "def process_img(img, size = (224,224)):\n",
    "    img = cv2.resize(img, size)\n",
    "    img = img/255\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc931ef-85df-4292-b107-fb63bb8605a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = datasetpath\n",
    "images, values = [],[]\n",
    "for name in os.listdir(path):\n",
    "    for name2 in os.listdir(os.path.join(path, name)):\n",
    "        if not name2.startswith('.'):\n",
    "            img = cv2.imread(os.path.join(path, name, name2), cv2.IMREAD_GRAYSCALE)\n",
    "            images.append(process_img(img))\n",
    "            values.append(name.replace(', ', '_'))\n",
    "            \n",
    "more_images, more_values = images, values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data with string labels\n",
    "orijinal_liste = more_values\n",
    "labels = sorted(list(set(orijinal_liste)))\n",
    "print(labels)\n",
    "label_encoder = LabelEncoder()\n",
    "numerical_labels = label_encoder.fit_transform(labels)\n",
    "for label, numerical_label in zip(labels, numerical_labels):\n",
    "    print(f'{label} -> {numerical_label}')\n",
    "arr = []\n",
    "for i in more_values:\n",
    "    arr.append(labels.index(i))\n",
    "more_values = arr\n",
    "\n",
    "more_images = np.array(more_images)\n",
    "more_values = np.array(more_values) \n",
    "\n",
    "more_images = np.repeat(more_images[..., np.newaxis], 3, -1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(more_images, arr, test_size=0.5, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.6, random_state=42)\n",
    "\n",
    "y_val = np.array(y_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b76b0-b63d-40ec-8a85-09174e63e91c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import ResNet152V2\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff0e55-f0aa-4489-a26e-6741aca31475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_val = np.array(y_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58109a5-4939-499c-8f94-2a0a48633256",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet152V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "num_classes = len(labels)\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Adjust num_classes based on your dataset\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer, loss=tf.losses.SparseCategoricalCrossentropy(), metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()\n",
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "y_val = np.array(y_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=15, validation_data=(x_val, y_val), verbose=1, callbacks=[tensorboard_callback]) \n",
    "model_path = 'gray.h5'\n",
    "model.save(os.path.join('models',model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d246d-a541-422d-b91d-af1278939000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# One-hot encode y_test\n",
    "y_test_hot = to_categorical(y_test, num_classes=len(labels))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test_hot, axis=1)\n",
    "\n",
    "f1 = f1_score(np.argmax(y_test_hot, axis=1), y_pred_classes, average='weighted')\n",
    "print(\"F1-score: \", f1)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(confusion_mtx, annot=True, xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bd515-b943-49be-85c2-310f7d01d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(image, size = (224,224)):\n",
    "    image = cv2.resize(image, size)\n",
    "    equalized_image = cv2.equalizeHist(image)\n",
    "    equalized_image = equalized_image/255\n",
    "    return equalized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d68171-4b14-4938-83d7-a66f1120a8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = datasetpath\n",
    "images, values = [],[]\n",
    "for name in os.listdir(path):\n",
    "    for name2 in os.listdir(os.path.join(path, name)):\n",
    "        if not name2.startswith('.'):\n",
    "            img = cv2.imread(os.path.join(path, name, name2), cv2.IMREAD_GRAYSCALE)\n",
    "            images.append(histogram_equalization(img))\n",
    "            values.append(name.replace(', ', '_'))\n",
    "            \n",
    "more_images, more_values = images, values\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data with string labels\n",
    "orijinal_liste = more_values\n",
    "labels = sorted(list(set(orijinal_liste)))\n",
    "print(labels)\n",
    "label_encoder = LabelEncoder()\n",
    "numerical_labels = label_encoder.fit_transform(labels)\n",
    "for label, numerical_label in zip(labels, numerical_labels):\n",
    "    print(f'{label} -> {numerical_label}')\n",
    "arr = []\n",
    "for i in more_values:\n",
    "    arr.append(labels.index(i))\n",
    "more_values = arr\n",
    "\n",
    "more_images = np.array(more_images)\n",
    "more_values = np.array(more_values) \n",
    "\n",
    "more_images = np.repeat(more_images[..., np.newaxis], 3, -1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(more_images, arr, test_size=0.5, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.6, random_state=42)\n",
    "\n",
    "y_val = np.array(y_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b318224-c9cb-4fae-a1b9-11e7d2759861",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet152V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "num_classes = len(labels)\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Adjust num_classes based on your dataset\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer, loss=tf.losses.SparseCategoricalCrossentropy(), metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()\n",
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=15, validation_data=(x_val, y_val), verbose=1, callbacks=[tensorboard_callback]) \n",
    "model_path = 'histo.h5'\n",
    "model.save(os.path.join('models',model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8783a9-63c3-4a99-aab7-749c978fb838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# One-hot encode y_test\n",
    "y_test_hot = to_categorical(y_test, num_classes=len(labels))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test_hot, axis=1)\n",
    "\n",
    "f1 = f1_score(np.argmax(y_test_hot, axis=1), y_pred_classes, average='weighted')\n",
    "print(\"F1-score: \", f1)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(confusion_mtx, annot=True, xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9746293-c9cb-417b-a5e7-0810ef7f0c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_morphological_gradient(image, kernel_size=3, size = (224,224)):\n",
    "    image = cv2.resize(image, size)\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    dilation = cv2.dilate(image, kernel, iterations=5)\n",
    "    erosion = cv2.erode(image, kernel, iterations=1)\n",
    "    gradient_image = cv2.subtract(dilation, erosion)\n",
    "    gradient_image = gradient_image/255\n",
    "    return gradient_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a927b43c-f02b-43e5-ae15-d4de295c18b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = datasetpath\n",
    "images, values = [],[]\n",
    "for name in os.listdir(path):\n",
    "    for name2 in os.listdir(os.path.join(path, name)):\n",
    "        if not name2.startswith('.'):\n",
    "            img = cv2.imread(os.path.join(path, name, name2), cv2.IMREAD_GRAYSCALE)\n",
    "            images.append(compute_morphological_gradient(img))\n",
    "            values.append(name.replace(', ', '_'))\n",
    "            \n",
    "more_images, more_values = images, values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Sample data with string labels\n",
    "orijinal_liste = more_values\n",
    "labels = sorted(list(set(orijinal_liste)))\n",
    "print(labels)\n",
    "label_encoder = LabelEncoder()\n",
    "numerical_labels = label_encoder.fit_transform(labels)\n",
    "for label, numerical_label in zip(labels, numerical_labels):\n",
    "    print(f'{label} -> {numerical_label}')\n",
    "arr = []\n",
    "for i in more_values:\n",
    "    arr.append(labels.index(i))\n",
    "more_values = arr\n",
    "\n",
    "more_images = np.array(more_images)\n",
    "more_values = np.array(more_values) \n",
    "\n",
    "more_images = np.repeat(more_images[..., np.newaxis], 3, -1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(more_images, arr, test_size=0.5, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.6, random_state=42)\n",
    "\n",
    "y_val = np.array(y_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a45851-55d5-4da1-a6f2-4508291dbf54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = ResNet152V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "num_classes = len(labels)\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Adjust num_classes based on your dataset\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer, loss=tf.losses.SparseCategoricalCrossentropy(), metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()\n",
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=15, validation_data=(x_val, y_val), verbose=1, callbacks=[tensorboard_callback]) \n",
    "model_path = 'morpho.h5'\n",
    "model.save(os.path.join('models',model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c8790-4c90-4c23-a7d7-c515946ae87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# One-hot encode y_test\n",
    "y_test_hot = to_categorical(y_test, num_classes=len(labels))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test_hot, axis=1)\n",
    "\n",
    "f1 = f1_score(np.argmax(y_test_hot, axis=1), y_pred_classes, average='weighted')\n",
    "print(\"F1-score: \", f1)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(confusion_mtx, annot=True, xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57571cda-27e2-4f38-bc2d-a8d827b2509c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_dtm(image, threshold=28, size = (224, 224)):\n",
    "    # Görüntüyü yükle\n",
    "    input_image = cv2.resize(image, size)\n",
    "\n",
    "    # Sobel türevlerini hesapla\n",
    "    sobelx = cv2.Sobel(input_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(input_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Gradient magnitude hesapla\n",
    "    dtm = np.sqrt(sobelx**2 + sobely**2)\n",
    "\n",
    "    # Eşikleme uygula\n",
    "    dtm_thresholded = np.where(dtm > threshold, 255, 0).astype(np.uint8)\n",
    "    dtm_thresholded = dtm_thresholded/255\n",
    "    return dtm_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe3b89-d9d7-4a71-9390-df3ce3b940b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = datasetpath\n",
    "images, values = [],[]\n",
    "for name in os.listdir(path):\n",
    "    for name2 in os.listdir(os.path.join(path, name)):\n",
    "        if not name2.startswith('.'):\n",
    "            img = cv2.imread(os.path.join(path, name, name2), cv2.IMREAD_GRAYSCALE)\n",
    "            images.append(calculate_dtm(img))\n",
    "            values.append(name.replace(', ', '_'))\n",
    "            \n",
    "more_images, more_values = images, values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Sample data with string labels\n",
    "orijinal_liste = more_values\n",
    "labels = sorted(list(set(orijinal_liste)))\n",
    "print(labels)\n",
    "label_encoder = LabelEncoder()\n",
    "numerical_labels = label_encoder.fit_transform(labels)\n",
    "for label, numerical_label in zip(labels, numerical_labels):\n",
    "    print(f'{label} -> {numerical_label}')\n",
    "arr = []\n",
    "for i in more_values:\n",
    "    arr.append(labels.index(i))\n",
    "more_values = arr\n",
    "\n",
    "more_images = np.array(more_images)\n",
    "more_values = np.array(more_values) \n",
    "\n",
    "more_images = np.repeat(more_images[..., np.newaxis], 3, -1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(more_images, arr, test_size=0.5, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.6, random_state=42)\n",
    "\n",
    "y_val = np.array(y_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eeb7ee-0f33-4067-88ba-8cd6efad0492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = ResNet152V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "num_classes = len(labels)\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Adjust num_classes based on your dataset\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer, loss=tf.losses.SparseCategoricalCrossentropy(), metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()\n",
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=15, validation_data=(x_val, y_val), verbose=1, callbacks=[tensorboard_callback]) \n",
    "model_path = 'dtm.h5'\n",
    "model.save(os.path.join('models',model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e4bc5-56d5-490d-9c5f-bc5b50c11ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# One-hot encode y_test\n",
    "y_test_hot = to_categorical(y_test, num_classes=len(labels))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test_hot, axis=1)\n",
    "\n",
    "f1 = f1_score(np.argmax(y_test_hot, axis=1), y_pred_classes, average='weighted')\n",
    "print(\"F1-score: \", f1)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(confusion_mtx, annot=True, xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0fec99-a1c9-478c-9dbb-d340e9ed7250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_hog(image, pixels_per_cell=(16, 16), size = (224, 224)):\n",
    "    image = cv2.resize(image, size)\n",
    "    # Compute HOG features with higher resolution\n",
    "    hog_features, hog_image = feature.hog(image, visualize=True, pixels_per_cell=pixels_per_cell)\n",
    "    # Enhance the contrast of the HOG image\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 28))\n",
    "\n",
    "    return hog_image_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a35b6-46e6-4986-beec-b22790d951d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = datasetpath\n",
    "images, values = [],[]\n",
    "for name in os.listdir(path):\n",
    "    for name2 in os.listdir(os.path.join(path, name)):\n",
    "        if not name2.startswith('.'):\n",
    "            img = cv2.imread(os.path.join(path, name, name2), cv2.IMREAD_GRAYSCALE)\n",
    "            images.append(compute_hog(img))\n",
    "            values.append(name.replace(', ', '_'))\n",
    "            \n",
    "more_images, more_values = images, values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Sample data with string labels\n",
    "orijinal_liste = more_values\n",
    "labels = sorted(list(set(orijinal_liste)))\n",
    "print(labels)\n",
    "label_encoder = LabelEncoder()\n",
    "numerical_labels = label_encoder.fit_transform(labels)\n",
    "for label, numerical_label in zip(labels, numerical_labels):\n",
    "    print(f'{label} -> {numerical_label}')\n",
    "arr = []\n",
    "for i in more_values:\n",
    "    arr.append(labels.index(i))\n",
    "more_values = arr\n",
    "\n",
    "more_images = np.array(more_images)\n",
    "more_values = np.array(more_values) \n",
    "\n",
    "more_images = np.repeat(more_images[..., np.newaxis], 3, -1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(more_images, arr, test_size=0.5, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.6, random_state=42)\n",
    "\n",
    "y_val = np.array(y_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef25e7b-f98f-4278-8622-8ca760bb8fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = ResNet152V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "num_classes = len(labels)\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Adjust num_classes based on your dataset\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer, loss=tf.losses.SparseCategoricalCrossentropy(), metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()\n",
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=15, validation_data=(x_val, y_val), verbose=1, callbacks=[tensorboard_callback]) \n",
    "model_path = 'hog.h5'\n",
    "model.save(os.path.join('models',model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd455aad-a006-4ce3-a630-f2dc2c3922f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# One-hot encode y_test\n",
    "y_test_hot = to_categorical(y_test, num_classes=len(labels))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test_hot, axis=1)\n",
    "\n",
    "f1 = f1_score(np.argmax(y_test_hot, axis=1), y_pred_classes, average='weighted')\n",
    "print(\"F1-score: \", f1)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(confusion_mtx, annot=True, xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
